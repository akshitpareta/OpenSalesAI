# =============================================================================
# OpenSalesAI — Full Stack Docker Compose
# =============================================================================
# Usage:
#   cp .env.example .env   (then edit values)
#   docker compose up -d
#   docker compose ps      (verify all services healthy)
# =============================================================================

name: opensalesai

services:
  # ---------------------------------------------------------------------------
  # PostgreSQL 16 — Primary Database + TimescaleDB
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:16-alpine
    container_name: opensalesai-postgres
    restart: unless-stopped
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-opensalesai}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-opensalesai_secret}
      POSTGRES_DB: ${POSTGRES_DB:-opensalesai}
      POSTGRES_MULTIPLE_DATABASES: ${POSTGRES_DB:-opensalesai},keycloak,n8n,mlflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infra/docker/postgres/init-multiple-dbs.sh:/docker-entrypoint-initdb.d/init-multiple-dbs.sh:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-opensalesai} -d ${POSTGRES_DB:-opensalesai}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Redis 7 — Cache, Message Broker, Task Queue
  # ---------------------------------------------------------------------------
  redis:
    image: redis:7-alpine
    container_name: opensalesai-redis
    restart: unless-stopped
    ports:
      - "${REDIS_PORT:-6379}:6379"
    command: >
      redis-server
      --requirepass ${REDIS_PASSWORD:-opensalesai_redis}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-opensalesai_redis}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Qdrant — Vector Database for RAG
  # ---------------------------------------------------------------------------
  qdrant:
    image: qdrant/qdrant:latest
    container_name: opensalesai-qdrant
    restart: unless-stopped
    ports:
      - "${QDRANT_REST_PORT:-6333}:6333"
      - "${QDRANT_GRPC_PORT:-6334}:6334"
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__STORAGE__STORAGE_PATH: /qdrant/storage
      QDRANT__STORAGE__SNAPSHOTS_PATH: /qdrant/snapshots
    volumes:
      - qdrant_storage:/qdrant/storage
      - qdrant_snapshots:/qdrant/snapshots
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:6333/healthz || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # MinIO — S3-Compatible Object Storage
  # ---------------------------------------------------------------------------
  minio:
    image: minio/minio:latest
    container_name: opensalesai-minio
    restart: unless-stopped
    ports:
      - "${MINIO_API_PORT:-9000}:9000"
      - "${MINIO_CONSOLE_PORT:-9001}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-opensalesai}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-opensalesai_minio_secret}
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Keycloak — Identity & Access Management (SSO, RBAC)
  # ---------------------------------------------------------------------------
  keycloak:
    image: quay.io/keycloak/keycloak:latest
    container_name: opensalesai-keycloak
    restart: unless-stopped
    ports:
      - "${KEYCLOAK_PORT:-8080}:8080"
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: ${POSTGRES_USER:-opensalesai}
      KC_DB_PASSWORD: ${POSTGRES_PASSWORD:-opensalesai_secret}
      KC_HOSTNAME_STRICT: "false"
      KC_HTTP_ENABLED: "true"
      KC_PROXY_HEADERS: xforwarded
      KEYCLOAK_ADMIN: ${KEYCLOAK_ADMIN_USER:-admin}
      KEYCLOAK_ADMIN_PASSWORD: ${KEYCLOAK_ADMIN_PASSWORD:-admin_secret}
    command: start-dev
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "exec 3<>/dev/tcp/127.0.0.1/8080; echo -e 'GET /health/ready HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3; cat <&3 | grep -q '200\\|UP'"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 60s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # n8n — Workflow Automation Engine
  # ---------------------------------------------------------------------------
  n8n:
    image: n8nio/n8n:latest
    container_name: opensalesai-n8n
    restart: unless-stopped
    ports:
      - "${N8N_PORT:-5678}:5678"
    environment:
      N8N_HOST: ${N8N_HOST:-localhost}
      N8N_PORT: 5678
      N8N_PROTOCOL: http
      NODE_ENV: production
      WEBHOOK_URL: ${N8N_WEBHOOK_URL:-http://localhost:5678/}
      DB_TYPE: postgresdb
      DB_POSTGRESDB_HOST: postgres
      DB_POSTGRESDB_PORT: 5432
      DB_POSTGRESDB_DATABASE: n8n
      DB_POSTGRESDB_USER: ${POSTGRES_USER:-opensalesai}
      DB_POSTGRESDB_PASSWORD: ${POSTGRES_PASSWORD:-opensalesai_secret}
      EXECUTIONS_DATA_SAVE_ON_ERROR: all
      EXECUTIONS_DATA_SAVE_ON_SUCCESS: all
      EXECUTIONS_DATA_SAVE_MANUAL_EXECUTIONS: "true"
      N8N_ENCRYPTION_KEY: ${N8N_ENCRYPTION_KEY:-change-me-to-a-random-string}
      QUEUE_BULL_REDIS_HOST: redis
      QUEUE_BULL_REDIS_PORT: 6379
      QUEUE_BULL_REDIS_PASSWORD: ${REDIS_PASSWORD:-opensalesai_redis}
    volumes:
      - n8n_data:/home/node/.n8n
      - ./workflows:/home/node/workflows:ro
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:5678/healthz || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Caddy — Reverse Proxy with Auto-TLS
  # ---------------------------------------------------------------------------
  caddy:
    image: caddy:latest
    container_name: opensalesai-caddy
    restart: unless-stopped
    ports:
      - "${CADDY_HTTP_PORT:-80}:80"
      - "${CADDY_HTTPS_PORT:-443}:443"
    volumes:
      - ./infra/Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - keycloak
      - n8n
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Ollama — Local LLM Inference (GPU-accelerated)
  # ---------------------------------------------------------------------------
  ollama:
    image: ollama/ollama:latest
    container_name: opensalesai-ollama
    restart: unless-stopped
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      OLLAMA_HOST: 0.0.0.0
      OLLAMA_NUM_PARALLEL: ${OLLAMA_NUM_PARALLEL:-4}
      OLLAMA_MAX_LOADED_MODELS: ${OLLAMA_MAX_LOADED_MODELS:-2}
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/api/tags || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Prometheus — Metrics Collection
  # ---------------------------------------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: opensalesai-prometheus
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=30d"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--web.enable-lifecycle"
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:9090/-/healthy || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 15s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # Grafana — Dashboards & Visualization
  # ---------------------------------------------------------------------------
  grafana:
    image: grafana/grafana:latest
    container_name: opensalesai-grafana
    restart: unless-stopped
    ports:
      - "${GRAFANA_PORT:-3001}:3000"
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin_secret}
      GF_SERVER_ROOT_URL: ${GRAFANA_ROOT_URL:-http://localhost:3001}
      GF_INSTALL_PLUGINS: grafana-clock-panel,grafana-piechart-panel
      GF_AUTH_GENERIC_OAUTH_ENABLED: "true"
      GF_AUTH_GENERIC_OAUTH_NAME: Keycloak
      GF_AUTH_GENERIC_OAUTH_CLIENT_ID: grafana
      GF_AUTH_GENERIC_OAUTH_SCOPES: openid profile email
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:3000/api/health || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - opensalesai-net

  # ---------------------------------------------------------------------------
  # MLflow — ML Experiment Tracking & Model Registry
  # ---------------------------------------------------------------------------
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    container_name: opensalesai-mlflow
    restart: unless-stopped
    ports:
      - "${MLFLOW_PORT:-5000}:5000"
    environment:
      MLFLOW_BACKEND_STORE_URI: postgresql://${POSTGRES_USER:-opensalesai}:${POSTGRES_PASSWORD:-opensalesai_secret}@postgres:5432/mlflow
      MLFLOW_DEFAULT_ARTIFACT_ROOT: s3://mlflow-artifacts/
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-opensalesai}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-opensalesai_minio_secret}
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri postgresql://${POSTGRES_USER:-opensalesai}:${POSTGRES_PASSWORD:-opensalesai_secret}@postgres:5432/mlflow
      --default-artifact-root s3://mlflow-artifacts/
    depends_on:
      postgres:
        condition: service_healthy
      minio:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5000/health || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - opensalesai-net

# =============================================================================
# Volumes — Persistent Data Storage
# =============================================================================
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  qdrant_storage:
    driver: local
  qdrant_snapshots:
    driver: local
  minio_data:
    driver: local
  n8n_data:
    driver: local
  caddy_data:
    driver: local
  caddy_config:
    driver: local
  ollama_models:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

# =============================================================================
# Networks
# =============================================================================
networks:
  opensalesai-net:
    driver: bridge
    name: opensalesai-net
